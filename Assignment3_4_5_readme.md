##########################################################################
Assignment 3 
Data was fetched from the sklearn itself
where the data is taken to dataframe for prepeocessing
Basic checking of the data with info(),shape,describe()
Then checked for nullvalues and duplicate values.Since no duplicate or null values where ther no need to handle it
Then the data was differntated into two sets numerical and non numerical.But only numericla values where present
Then skewness was checked with skew and hist to look for outliers
outliers was found and it was removed 
Then log method was used to bring the data to the range
Then minmax scaler was found 
Then data was splittd to test and train where test data was 0.2
Then regression methods where used to  create models
Linear Regression
Decission Tree
Random Forest Regressor
Gradient Boosting Regressor
Support Vector Regressor (SVR)
Then MOdel was evaluated with certian methods to check the error or how it is performed


##########################################################################
Assignment 4
Data was fetched from the sklearn
where the data is taken to dataframe for prepeocessing
Basic checking of the data with info(),shape,describe()
Then checked for nullvalues and duplicate values.Since no duplicate or null values where ther no need to handle it
Then the data was differntated into two sets numerical and non numerical.But only numericla values where present
Then skewness was checked with skew and hist to look for outliers

quantile method was used to remove outliers 
z score method was also used of x values
Then  standard scalred was used 
Then data was splittd to test and train where test data was 0.2
all was assignment to the algortithams1. Logistic Regression 2. Decision Tree Classifier 3. Random Forest Classifier 4. Support Vector Machine (SVM) 5. k-Nearest Neighbors (k-NN)

############################################################################
Assignment 5
Data was fetched from the sklearn
where the data is taken to dataframe for prepeocessing
Basic checking of the data with info(),shape,describe()
Then checked for nullvalues and duplicate values.
Duplicate value was handled
Data was taken to Kmean and AgglomerativeClustering 
line chart and dendrogram was drown out of the data
